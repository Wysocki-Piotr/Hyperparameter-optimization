{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5cdfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9cd475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search - Loaded from files:\n",
      "  Bank: 0.1858421833675464\n",
      "  Gym: 0.1534136800030513\n",
      "  Heart Disease: 0.1277791441181989\n",
      "  Titanic: 0.1104537560930364\n"
     ]
    }
   ],
   "source": [
    "# Load Random Search results from best_models_summary.csv\n",
    "rs_best_models = pd.read_csv('RandomForestData/best_models_summary.csv')\n",
    "\n",
    "# Extract baseline brier scores (these are from RandomForest.ipynb baseline runs)\n",
    "baseline_brier_scores = [0.1892, 0.1819, 0.1067, 0.1520]  # Bank, Gym, Heart Disease, Titanic\n",
    "\n",
    "# Extract Random Search best parameters and test scores for each dataset\n",
    "import ast\n",
    "\n",
    "random_brier_adj = []\n",
    "random_best_params = []\n",
    "\n",
    "for dataset_name in ['Bank', 'Gym', 'Heart Disease', 'Titanic']:\n",
    "    row = rs_best_models[rs_best_models['dataset'] == dataset_name].iloc[0]\n",
    "    random_brier_adj.append(row['brier_score'])\n",
    "    random_best_params.append(ast.literal_eval(row['params']))\n",
    "\n",
    "print(\"Random Search - Loaded from files:\")\n",
    "for ds, brier in zip(['Bank', 'Gym', 'Heart Disease', 'Titanic'], random_brier_adj):\n",
    "    print(f\"  {ds}: {brier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce18aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bayesian Optimization - Loaded from files:\n",
      "  Bank: 0.1843225378562384\n",
      "  Gym: 0.1786213871377209\n",
      "  Heart Disease: 0.1044106469027575\n",
      "  Titanic: 0.1520592793866828\n"
     ]
    }
   ],
   "source": [
    "# Load Bayesian Optimization results from all_bayesian_results.csv\n",
    "bayes_results = pd.read_csv('RandomForestData/all_bayesian_results.csv')\n",
    "\n",
    "# Extract Bayesian best parameters and test scores for each dataset\n",
    "bayes_brier_adj = []\n",
    "bayes_best_params = []\n",
    "\n",
    "for dataset_name in ['Bank', 'Gym', 'Heart Disease', 'Titanic']:\n",
    "    # Filter for this dataset and completed trials\n",
    "    ds_trials = bayes_results[bayes_results['dataset'] == dataset_name]\n",
    "    ds_completed = ds_trials[ds_trials['state'] == 1]  # State 1 = COMPLETE\n",
    "    \n",
    "    # Get best trial (lowest brier_score)\n",
    "    best_trial = ds_completed.loc[ds_completed['brier_score'].idxmin()]\n",
    "    \n",
    "    # Extract test brier score (unique per dataset)\n",
    "    bayes_brier_adj.append(best_trial['test_brier_score'])\n",
    "    \n",
    "    # Extract parameters\n",
    "    params = {\n",
    "        'n_estimators': int(best_trial['n_estimators']),\n",
    "        'criterion': best_trial['criterion'],\n",
    "        'max_depth': None if pd.isna(best_trial['max_depth']) else int(best_trial['max_depth']),\n",
    "        'min_samples_split': int(best_trial['min_samples_split']),\n",
    "        'min_samples_leaf': int(best_trial['min_samples_leaf']),\n",
    "        'max_features': best_trial['max_features'] if best_trial['max_features'] == 'sqrt' else float(best_trial['max_features']),\n",
    "        'max_samples': None if pd.isna(best_trial['max_samples']) else float(best_trial['max_samples'])\n",
    "    }\n",
    "    bayes_best_params.append(params)\n",
    "\n",
    "print(\"\\nBayesian Optimization - Loaded from files:\")\n",
    "for ds, brier in zip(['Bank', 'Gym', 'Heart Disease', 'Titanic'], bayes_brier_adj):\n",
    "    print(f\"  {ds}: {brier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c92dc120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Search dict created from files:\n",
      "  Datasets: ['bank', 'gym', 'heart', 'titanic']\n",
      "  Brier scores: [np.float64(0.1858421833675464), np.float64(0.1534136800030513), np.float64(0.1277791441181989), np.float64(0.1104537560930364)]\n"
     ]
    }
   ],
   "source": [
    "# Create random dict from loaded data\n",
    "random = {\n",
    "    'dataset': ['bank', 'gym', 'heart', 'titanic'],\n",
    "    'brier_adj': random_brier_adj,\n",
    "    'baseline_brier': baseline_brier_scores,\n",
    "    'best_params': random_best_params\n",
    "}\n",
    "\n",
    "print(\"\\nRandom Search dict created from files:\")\n",
    "print(f\"  Datasets: {random['dataset']}\")\n",
    "print(f\"  Brier scores: {random['brier_adj']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d5bc215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bayesian Optimization dict created from files:\n",
      "  Datasets: ['bank', 'gym', 'heart', 'titanic']\n",
      "  Brier scores: [np.float64(0.1843225378562384), np.float64(0.1786213871377209), np.float64(0.1044106469027575), np.float64(0.1520592793866828)]\n"
     ]
    }
   ],
   "source": [
    "# Create bayes dict from loaded data\n",
    "bayes = {\n",
    "    'dataset': ['bank', 'gym', 'heart', 'titanic'],\n",
    "    'brier_adj': bayes_brier_adj,\n",
    "    'baseline_brier': baseline_brier_scores,\n",
    "    'best_params': bayes_best_params\n",
    "}\n",
    "\n",
    "print(\"\\nBayesian Optimization dict created from files:\")\n",
    "print(f\"  Datasets: {bayes['dataset']}\")\n",
    "print(f\"  Brier scores: {bayes['brier_adj']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "741bfed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_df = pd.DataFrame(bayes)\n",
    "random_df = pd.DataFrame(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6052bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"preprocessed_datasets/bank_data.csv\")\n",
    "y1 = pd.read_csv(\"preprocessed_datasets/bank_target.csv\").squeeze()\n",
    "X2 = pd.read_csv(\"preprocessed_datasets/gym_data.csv\")\n",
    "y2 = pd.read_csv(\"preprocessed_datasets/gym_target.csv\").squeeze()\n",
    "X3 = pd.read_csv(\"preprocessed_datasets/heartDisease_data.csv\")\n",
    "y3 = pd.read_csv(\"preprocessed_datasets/heartDisease_target.csv\").squeeze()\n",
    "X4 = pd.read_csv(\"preprocessed_datasets/titanic_data.csv\")\n",
    "y4 = pd.read_csv(\"preprocessed_datasets/titanic_target.csv\").squeeze()\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=42, stratify=y4)\n",
    "\n",
    "\n",
    "datasets = [(X1_train, X1_test, y1_train, y1_test),\n",
    "            (X2_train, X2_test, y2_train, y2_test),\n",
    "            (X3_train, X3_test, y3_train, y3_test),\n",
    "            (X4_train, X4_test, y4_train, y4_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0e1dd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>brier_adj</th>\n",
       "      <th>baseline_brier</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>0.185842</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gym</td>\n",
       "      <td>0.153414</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': None, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>titanic</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>0.184323</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>{'n_estimators': 1375, 'criterion': 'entropy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gym</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>{'n_estimators': 412, 'criterion': 'log_loss',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.104411</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>{'n_estimators': 1449, 'criterion': 'entropy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>titanic</td>\n",
       "      <td>0.152059</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>{'n_estimators': 1216, 'criterion': 'log_loss'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  brier_adj  baseline_brier  \\\n",
       "0     bank   0.185842          0.1892   \n",
       "1      gym   0.153414          0.1819   \n",
       "2    heart   0.127779          0.1067   \n",
       "3  titanic   0.110454          0.1520   \n",
       "0     bank   0.184323          0.1892   \n",
       "1      gym   0.178621          0.1819   \n",
       "2    heart   0.104411          0.1067   \n",
       "3  titanic   0.152059          0.1520   \n",
       "\n",
       "                                         best_params  \n",
       "0  {'criterion': 'entropy', 'max_depth': None, 'm...  \n",
       "1  {'criterion': 'log_loss', 'max_depth': None, '...  \n",
       "2  {'criterion': 'entropy', 'max_depth': 10, 'max...  \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'm...  \n",
       "0  {'n_estimators': 1375, 'criterion': 'entropy',...  \n",
       "1  {'n_estimators': 412, 'criterion': 'log_loss',...  \n",
       "2  {'n_estimators': 1449, 'criterion': 'entropy',...  \n",
       "3  {'n_estimators': 1216, 'criterion': 'log_loss'...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([random_df, bayes_df])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a157320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayes:    0.1843225378562384 \n",
      "random:    0.18471559600566623 \n",
      "bayes:    0.17862138713772094 \n",
      "random:    0.17750083281720883 \n",
      "bayes:    0.1044106469027575 \n",
      "random:    0.10497195672091833 \n",
      "bayes:    0.1520592793866828 \n",
      "random:    0.15155394282929383 \n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    bayes_params = bayes_best_params[i]\n",
    "    random_params = random_best_params[i]\n",
    "    \n",
    "    model = RandomForestClassifier(**bayes_params, random_state=42, n_jobs=-1)\n",
    "    model.fit(datasets[i][0], datasets[i][2])\n",
    "    print(f\"bayes:    {brier_score_loss(datasets[i][3], model.predict_proba(datasets[i][1])[:, 1]) } \")\n",
    "\n",
    "\n",
    "    model = RandomForestClassifier(**random_params, random_state=42, n_jobs=-1)\n",
    "    model.fit(datasets[i][0], datasets[i][2])\n",
    "    print(f\"random:    {brier_score_loss(datasets[i][3], model.predict_proba(datasets[i][1])[:, 1]) } \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
